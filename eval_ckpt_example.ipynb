{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e2039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_ckpt_example.py - single image inference for EfficientNet\n",
    "# adapted from TF → PyTorch\n",
    "\n",
    "\n",
    "# imports \n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "\n",
    "# project-specific imports\n",
    "from ModelBuilder import efficientnet\n",
    "from utils import load_model_weights  # optional: load pretrained weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596c5891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# device \n",
    "# adapted: TF device handling → PyTorch device handling\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf11727",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#transforms \n",
    "# reused from main training/eval pipeline\n",
    "# ensures preprocessing consistency with dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # match input size of B0 (adjustable for B1-B8, L2)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],  # ImageNet normalization\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7783b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# single image loader \n",
    "def load_image(img_path):\n",
    "    \"\"\"Load and preprocess a single image.\"\"\"\n",
    "    image = Image.open(img_path).convert('RGB')  # ensure 3 channels\n",
    "    image = transform(image)\n",
    "    return image.unsqueeze(0).to(device)  # add batch dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9883895a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built model: efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (stem_conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (stem_bn): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (activation): Swish()\n",
       "  (blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (depthwise_conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (se_block): SEBlock(\n",
       "        (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): Swish()\n",
       "      )\n",
       "      (project_conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): Swish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (expand_conv): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn0): BatchNorm2d(96, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (depthwise_conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (se_block): SEBlock(\n",
       "        (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): Swish()\n",
       "      )\n",
       "      (project_conv): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(24, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): Swish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (expand_conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn0): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (depthwise_conv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "      (bn1): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (se_block): SEBlock(\n",
       "        (fc1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): Swish()\n",
       "      )\n",
       "      (project_conv): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(24, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): Swish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (expand_conv): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn0): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (depthwise_conv): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "      (bn1): BatchNorm2d(144, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (se_block): SEBlock(\n",
       "        (fc1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): Swish()\n",
       "      )\n",
       "      (project_conv): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(40, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): Swish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (expand_conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn0): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (depthwise_conv): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "      (bn1): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (se_block): SEBlock(\n",
       "        (fc1): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): Swish()\n",
       "      )\n",
       "      (project_conv): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(40, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): Swish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (expand_conv): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn0): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (depthwise_conv): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "      (bn1): BatchNorm2d(240, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (se_block): SEBlock(\n",
       "        (fc1): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): Swish()\n",
       "      )\n",
       "      (project_conv): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(80, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): Swish()\n",
       "    )\n",
       "    (6-7): 2 x MBConvBlock(\n",
       "      (expand_conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn0): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (depthwise_conv): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "      (bn1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (se_block): SEBlock(\n",
       "        (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): Swish()\n",
       "      )\n",
       "      (project_conv): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(80, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): Swish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (expand_conv): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn0): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (depthwise_conv): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "      (bn1): BatchNorm2d(480, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (se_block): SEBlock(\n",
       "        (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): Swish()\n",
       "      )\n",
       "      (project_conv): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(112, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): Swish()\n",
       "    )\n",
       "    (9-10): 2 x MBConvBlock(\n",
       "      (expand_conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn0): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (depthwise_conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "      (bn1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (se_block): SEBlock(\n",
       "        (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): Swish()\n",
       "      )\n",
       "      (project_conv): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(112, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): Swish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (expand_conv): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn0): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (depthwise_conv): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "      (bn1): BatchNorm2d(672, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (se_block): SEBlock(\n",
       "        (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): Swish()\n",
       "      )\n",
       "      (project_conv): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): Swish()\n",
       "    )\n",
       "    (12-14): 3 x MBConvBlock(\n",
       "      (expand_conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn0): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (depthwise_conv): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "      (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (se_block): SEBlock(\n",
       "        (fc1): Conv2d(1152, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(288, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): Swish()\n",
       "      )\n",
       "      (project_conv): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(192, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): Swish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (expand_conv): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn0): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (depthwise_conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "      (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (se_block): SEBlock(\n",
       "        (fc1): Conv2d(1152, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(288, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (activation): Swish()\n",
       "      )\n",
       "      (project_conv): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "      (activation): Swish()\n",
       "    )\n",
       "  )\n",
       "  (head_conv): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (head_bn): BatchNorm2d(1280, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1280, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# model setup \n",
    "model_name = 'efficientnet-b0'  # can change to b0-b8 or l2\n",
    "model = efficientnet(model_name=model_name)\n",
    "print(f\"Built model: {model_name}\")\n",
    "\n",
    "# adjust final layer for dataset\n",
    "num_classes = 9  # number of classes in your dataset\n",
    "in_features = model.fc.in_features  # input features to final linear layer\n",
    "model.fc = nn.Linear(in_features, num_classes)  # replace final layer\n",
    "model.to(device)\n",
    "model.eval()  # set to evaluation mode\n",
    "\n",
    "# optional: load pretrained weights if available\n",
    "# weight_path = \"path_to_pth_file.pth\"\n",
    "# if weight_path:\n",
    "#     model = load_model_weights(model, weight_path, device)\n",
    "# won't implement for now since this is a quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1415d48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 9])\n",
      "Probabilities: tensor([[0.1119, 0.1078, 0.1130, 0.1137, 0.1136, 0.1097, 0.1100, 0.1094, 0.1109]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Sum of probabilities: tensor(1.0000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  dummy run \n",
    "# dummy input for sanity check\n",
    "x = torch.randn(1, 3, 224, 224).to(device)\n",
    "y = model(x)\n",
    "print(\"Output shape:\", y.shape)  # expected: [1, 9]\n",
    "\n",
    "# convert output logits to probabilities\n",
    "probs = torch.softmax(y, dim=1)\n",
    "print(\"Probabilities:\", probs)\n",
    "print(\"Sum of probabilities:\", probs.sum())  # should be 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1beb517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  prediction function \n",
    "def predict(img_path, class_names):\n",
    "    \"\"\"Run inference on one image and print predicted class + probability.\"\"\"\n",
    "    img_tensor = load_image(img_path)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        pred_idx = torch.argmax(probs, dim=1).item()\n",
    "        pred_prob = probs[0, pred_idx].item()\n",
    "\n",
    "    print(f\"\\nImage: {img_path}\")\n",
    "    print(f\"Predicted: {class_names[pred_idx]}  ({pred_prob:.4f})\")\n",
    "\n",
    "    return pred_idx, pred_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8a4e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: C:\\Users\\nourh\\OneDrive\\Desktop\\EffecientNetProject\\Data\\Fish_Dataset\\Black Sea Sprat\\00001.png\n",
      "Predicted: Red Mullet  (0.1137)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 0.11371579021215439)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#  test prediction \n",
    "root_dir = r\"C:\\Users\\nourh\\OneDrive\\Desktop\\EffecientNetProject\\Data\\Fish_Dataset\"\n",
    "class_names = sorted(os.listdir(root_dir))  # get folder names as class labels\n",
    "\n",
    "test_image_path = os.path.join(root_dir, class_names[0], \"00001.png\")\n",
    "predict(test_image_path, class_names)  # untrained example; will be retrained later\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
